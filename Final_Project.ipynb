{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Customer Review Analysis\n",
    "## By. Andrew Simmons & Jingnan Jin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Reference\n",
    "0. marketplace\n",
    "1. customer_id\n",
    "2. review_id\n",
    "3. product_id\n",
    "4. product_parent\n",
    "5. product_title\n",
    "6. product_category\n",
    "7. star_rating - [1-5]\n",
    "8. helpful_votes\n",
    "9. total_votes\n",
    "10. vine\n",
    "11. verified_purchase\n",
    "12. review_headline\n",
    "13. review_body\n",
    "14. review_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid Modes: TEST or PROD\n",
    "\n",
    "MODE = \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import html\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if MODE == \"TEST\":\n",
    "    AWS_ACCESS_KEY_ID = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    AWS_SECRET_ACCESS_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    \n",
    "    import findspark\n",
    "    findspark.init()\n",
    "\n",
    "    # create entry points to spark\n",
    "    try:\n",
    "        sc.stop()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "    \n",
    "if MODE == \"TEST\":\n",
    "    conf = SparkConf().setAppName(\"AmazonCustomerReviewAnalysis\").setMaster(\"local[*]\")\n",
    "\n",
    "    sc = SparkContext(conf=conf)\n",
    "    sc._jsc.hadoopConfiguration().set(\"fs.s3.awsAccessKeyId\", AWS_ACCESS_KEY_ID)\n",
    "    sc._jsc.hadoopConfiguration().set(\"fs.s3.awsSecretAccessKey\", AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    spark = SparkSession(sparkContext=sc)\n",
    "elif MODE == \"PROD\":\n",
    "    conf = SparkConf().setAppName(\"AmazonCustomerReviewAnalysis\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Constants\"\"\"\n",
    "\n",
    "PLOT_DIMENSIONS = (20, 10)\n",
    "\n",
    "USELESS_WORDS = set([\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"PROD\":\n",
    "    dataset = spark.read.load(\"s3a://amazon-reviews-pds/parquet/\")\n",
    "    dataset = dataset.filter(dataset[\"marketplace\"] == \"US\")\n",
    "\n",
    "    categories = [row['product_category'] for row in dataset.select('product_category').distinct().collect()]\n",
    "\n",
    "    data_categories = {}\n",
    "    for category in categories:\n",
    "        data_categories[category] = dataset.filter(dataset['product_category'] == category).rdd.map(tuple).persist()\n",
    "elif MODE == \"TEST\":\n",
    "    #Process list of files to separate by category\n",
    "    data_dir = Path(\"sample_data\")\n",
    "    data_files = [\n",
    "        file\n",
    "        for file in data_dir.glob(\"*.tsv.gz\")\n",
    "        if file.name.startswith(\"amazon_reviews_us_\")\n",
    "    ]\n",
    "\n",
    "    data_categories = defaultdict(list)\n",
    "    for file in data_files:\n",
    "        category_name = file.name[18:-13].replace(\"_\", \" \")\n",
    "        data_categories[category_name].append(file)\n",
    "    \n",
    "    # Create mapping of category names to unioned RDD\n",
    "    for key, value in data_categories.items():\n",
    "        data_categories[key] = sc.union([sc.textFile(str(file)) for file in value])\n",
    "    \n",
    "    # Remove headers from data\n",
    "    for key, value in data_categories.items():\n",
    "        data_categories[key] = value.filter(lambda x: not x.startswith(\"marketplace\"))\n",
    "    \n",
    "    # Split TSV\n",
    "    for key, value in data_categories.items():\n",
    "        data_categories[key] = value.map(lambda x: x.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preprocess certain values\"\"\"\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "    data_categories[key] = value.map(\n",
    "        lambda x: (\n",
    "            x[0],\n",
    "            x[1],\n",
    "            x[2],\n",
    "            x[3],\n",
    "            x[4],\n",
    "            x[5],\n",
    "            x[6],\n",
    "            int(x[7]),\n",
    "            int(x[8]),\n",
    "            int(x[9]),\n",
    "            x[10],\n",
    "            x[11],\n",
    "            x[12],  # TODO: Determine if headlines are HTML escaped like the bodies\n",
    "            html.unescape(x[13]),\n",
    "            x[14],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate useful RDDs for future use\"\"\"\n",
    "\n",
    "# All categories unioned together\n",
    "def get_unioned_data(category_data):\n",
    "    rdds = []\n",
    "    for value in data_categories.values():\n",
    "        rdds.append(value)\n",
    "\n",
    "    return sc.union(rdds)\n",
    "\n",
    "\n",
    "unioned_data = get_unioned_data(data_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many records exist in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_counts = []\n",
    "for key, value in data_categories.items():\n",
    "    record_counts.append((key, value.count()))\n",
    "\n",
    "categories, counts = zip(*sorted(record_counts, key=itemgetter(1)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar(categories, counts)\n",
    "\n",
    "ax.set_title(\"Amazon Review Counts by Category\")\n",
    "ax.set_xlabel(\"Product Category\")\n",
    "ax.set_ylabel(\"Review Counts\")\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)\n",
    "    \n",
    "filename = 'records_in_each_category'\n",
    "fig.savefig(filename + '.pdf')\n",
    "fig.savefig(filename + '.png')\n",
    "\n",
    "if MODE == \"PROD\":\n",
    "    filename = 'records_in_each_category'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')\n",
    "\n",
    "print(f\"Total number of reviews in dataset: {sum(counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall, how satisfied are customers of each product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_review_by_category = []\n",
    "for key, value in data_categories.items():\n",
    "    star_ratings = value.map(lambda x: int(x[7]))\n",
    "    average_review_by_category.append((key, star_ratings.mean()))\n",
    "\n",
    "categories, ratings = zip(*sorted(average_review_by_category, key=itemgetter(1)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar(categories, ratings)\n",
    "\n",
    "ax.set_title(\"Average Product Category Rating\")\n",
    "ax.set_xlabel(\"Product Category\")\n",
    "ax.set_ylabel(\"Average Rating\")\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)\n",
    "    \n",
    "if MODE == \"PROD\":\n",
    "    filename = 'satisfaction_in_each_category'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the distribution of review scores change between product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_distributions = {}\n",
    "for key, value in data_categories.items():\n",
    "    review_distributions[key] = sorted(value.map(lambda x: (x[7], 1)).reduceByKey(lambda x, y: x + y).collect(), key=itemgetter(0))\n",
    "\n",
    "num_columns = 3\n",
    "\n",
    "fig, ax = plt.subplots(nrows=math.ceil(len(review_distributions.keys()) / num_columns),\n",
    "                       ncols=num_columns)\n",
    "fig.set_size_inches((20, 100))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (key, value) in enumerate(review_distributions.items()):\n",
    "    stars, counts = zip(*value)\n",
    "    \n",
    "    rects = ax[i].bar(stars, counts)\n",
    "    \n",
    "    # TODO: Calculate mean more efficiantly\n",
    "    total = 0\n",
    "    for j in range(len(stars)):\n",
    "        total += stars[j] * counts[j]\n",
    "    mean = total / sum(counts)\n",
    "    \n",
    "    # TODO: Include a median line\n",
    "    mean_line = ax[i].axvline(mean, color='red', linestyle='--')\n",
    "    ax[i].legend([mean_line], ['Mean Category Rating'])\n",
    "    \n",
    "    ax[i].set_title(f'Ratings Frequency Distribution for {key} category')\n",
    "    ax[i].set_xlabel('Star Rating')\n",
    "    ax[i].set_ylabel('Rating Count')\n",
    "\n",
    "if MODE == \"PROD\":\n",
    "    filename = 'review_scores_distribution_by_category'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are most used in each category at each rating for review headlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "category: {\n",
    "    1: [n most common words],\n",
    "    2: ...\n",
    "},\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_REVIEWS = {\"One Star\", \"Two Stars\", \"Three Stars\", \"Four Stars\", \"Five Stars\"}\n",
    "\n",
    "\n",
    "def remove_default_headlines(headline):\n",
    "    \"\"\"Remove default headlines\"\"\"\n",
    "    if headline in DEFAULT_REVIEWS:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess(headline):\n",
    "\n",
    "    # Remove HTML breaks\n",
    "    headline = re.sub(r\"<br \\/>\", \" \", headline)\n",
    "\n",
    "    # Convert multiple spaces to a single space\n",
    "    headline = re.sub(r\"\\s+\", \" \", headline, flags=re.I)\n",
    "\n",
    "    # Remove punctuation that is found at the end of words\n",
    "    headline = re.sub(r\"[,.!?]\", \"\", headline)\n",
    "\n",
    "    # Remove apostrophies as to group together both spellings of a word\n",
    "    headline = re.sub(r\"'\", \"\", headline)\n",
    "\n",
    "    return headline.lower()\n",
    "\n",
    "\n",
    "def remove_useless_words(headline_word):\n",
    "    \"\"\"Remove stop words and elipses\"\"\"\n",
    "\n",
    "    if headline_word in USELESS_WORDS:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_empty_words(headline_word):\n",
    "    if len(headline_word) == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_censored_swear_words(headline_word):\n",
    "    \"\"\"Amazon appears to have censored swear words by keeping the first character\n",
    "    and replacing the other characters with astrisks. These are not useful to us.\n",
    "    \"\"\"\n",
    "\n",
    "    if re.match(\"^[a-z]\\*+$\", headline_word) is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_words_without_alphanumeric(headline_word):\n",
    "    if re.match(\"[a-z0-9]\", headline_word) is None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# TODO: This doesn't seem to work 100% of the time\n",
    "def remove_numbers(headline_word):\n",
    "    \"\"\"Remove words that consist of nothing but numbers\"\"\"\n",
    "    if re.match(\"^[0-9]+$\", headline_word) is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_single_letter_words(headline_word):\n",
    "    if len(headline_word) == 1:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "POSSIBLE_RATINGS = [1, 2, 3, 4, 5]\n",
    "resulting_word_frequencies = defaultdict(dict)\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "\n",
    "    rating_words = {}\n",
    "\n",
    "    for i in POSSIBLE_RATINGS:\n",
    "\n",
    "        reviews = value.filter(lambda x: x[7] == i)\n",
    "\n",
    "        headlines = (\n",
    "            reviews.map(lambda x: x[12])\n",
    "            .filter(remove_default_headlines)\n",
    "            .map(preprocess)\n",
    "        )\n",
    "\n",
    "        headline_words = (\n",
    "            headlines.flatMap(lambda x: x.split())\n",
    "            .filter(remove_useless_words)\n",
    "            .filter(remove_empty_words)\n",
    "            .filter(remove_censored_swear_words)\n",
    "            .filter(remove_words_without_alphanumeric)\n",
    "            .filter(remove_single_letter_words)\n",
    "        )\n",
    "\n",
    "        word_frequencies = (\n",
    "            headline_words.map(lambda x: (x, 1))\n",
    "            .reduceByKey(lambda x, y: x + y)\n",
    "            .sortBy(lambda x: x[1], ascending=False)\n",
    "            .map(lambda x: x[0])\n",
    "        )\n",
    "\n",
    "        resulting_word_frequencies[key][i] = word_frequencies.take(3)\n",
    "\n",
    "# Output results\n",
    "\n",
    "for category in resulting_word_frequencies.keys():\n",
    "\n",
    "    print(f\"{category}:\")\n",
    "\n",
    "    for rating in POSSIBLE_RATINGS:\n",
    "\n",
    "        words = resulting_word_frequencies[category][rating]\n",
    "\n",
    "        print(f\"  {rating}: {list(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are most used in each category at each rating for review bodies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_word_frequencies = defaultdict(dict)\n",
    "for key, value in data_categories.items():\n",
    "    rating_words = {}\n",
    "    for i in POSSIBLE_RATINGS:\n",
    "        reviews = value.filter(lambda x: x[7] == i)\n",
    "        headlines = reviews.map(lambda x: x[13]).map(preprocess)\n",
    "\n",
    "        headline_words = (\n",
    "            headlines.flatMap(lambda x: x.split())\n",
    "            .filter(remove_useless_words)\n",
    "            .filter(remove_empty_words)\n",
    "            .filter(remove_censored_swear_words)\n",
    "            .filter(remove_words_without_alphanumeric)\n",
    "            .filter(remove_single_letter_words)\n",
    "        )\n",
    "        word_frequencies = (\n",
    "            headline_words.map(lambda x: (x, 1))\n",
    "            .reduceByKey(lambda x, y: x + y)\n",
    "            .sortBy(lambda x: x[1], ascending=False)\n",
    "            .map(lambda x: x[0])\n",
    "        )\n",
    "\n",
    "        resulting_word_frequencies[key][i] = word_frequencies.take(3)\n",
    "\n",
    "# Output results\n",
    "for category in resulting_word_frequencies.keys():\n",
    "    print(f\"{category}:\")\n",
    "    for rating in POSSIBLE_RATINGS:\n",
    "        words = resulting_word_frequencies[category][rating]\n",
    "        print(f\"  {rating}: {list(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the average rating in a category change between verified and unverified purchasers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = []\n",
    "for key, value in data_categories.items():\n",
    "    all_ratings_mean = value.map(lambda x: x[7]).mean()\n",
    "    verified_ratings_mean = (\n",
    "        value.filter(lambda x: x[11] == \"Y\").map(lambda x: x[7]).mean()\n",
    "    )\n",
    "    unverified_ratings_mean = (\n",
    "        value.filter(lambda x: x[11] == \"N\").map(lambda x: x[7]).mean()\n",
    "    )\n",
    "\n",
    "    mean_ratings.append(\n",
    "        (key, all_ratings_mean, verified_ratings_mean, unverified_ratings_mean)\n",
    "    )\n",
    "\n",
    "\n",
    "num_columns = 3\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=math.ceil(len(mean_ratings) / num_columns), ncols=num_columns\n",
    ")\n",
    "\n",
    "fig.set_size_inches((20, 100))\n",
    "ax = ax.flatten()\n",
    "\n",
    "labels = [\"All\", \"Verified\", \"Unverified\"]\n",
    "\n",
    "for i, category in enumerate(mean_ratings):\n",
    "    rects = ax[i].bar(labels, category[1:], color=[\"orange\", \"blue\", \"green\"])\n",
    "\n",
    "    ax[i].set_title(f'Average Rating in \"{category[0]}\" Category')\n",
    "    ax[i].set_xlabel(\"Review Type\")\n",
    "    ax[i].set_ylabel(\"Average Rating\")\n",
    "\n",
    "if MODE == \"PROD\":\n",
    "    filename = 'verified_vs_unverified_ratings'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"=== Differences between verified review average and unverified review average by stars ===\\n\"\n",
    ")\n",
    "\n",
    "# (category_name, average_difference)\n",
    "average_difference = []\n",
    "for category in mean_ratings:\n",
    "    category_name = category[0]\n",
    "    verified_review_average = category[2]\n",
    "    unverified_review_average = category[3]\n",
    "\n",
    "    average_difference.append(\n",
    "        (\n",
    "            category_name,\n",
    "            abs(abs(verified_review_average) - abs(unverified_ratings_mean)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Print differences by category\n",
    "for category in average_difference:\n",
    "    print(f\"{category[0]}: {category[1]}\")\n",
    "\n",
    "\n",
    "# Print total average differences\n",
    "_, difference = zip(*average_difference)\n",
    "print(f\"Overall: {sum(difference) / len(difference)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What review ratings to customers find the most helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (rating, (helpful_vote_percentage, 1))\n",
    "helpful_vote_percentage = unioned_data.filter(lambda x: x[9] != 0).map(\n",
    "    lambda x: (x[7], (x[8] / x[9], 1))\n",
    ")\n",
    "\n",
    "# (rating, average_helpful_vote_percentage)\n",
    "average_helpful_vote_percentage = helpful_vote_percentage.reduceByKey(\n",
    "    lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    ").map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "\n",
    "helpful_averages = sorted(average_helpful_vote_percentage.collect())\n",
    "rating, helpful_average = zip(*helpful_averages)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar(rating, helpful_average)\n",
    "\n",
    "ax.set_title(\"Average Helpfulness by Review Rating\")\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel(\"Average Helpfulness\")\n",
    "\n",
    "if MODE == \"PROD\":\n",
    "    filename = 'rating_helpfulness'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the Amazon Vine program influence customer reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_vine_rating = (\n",
    "    unioned_data.filter(lambda x: x[10] == \"Y\")\n",
    "    .map(lambda x: (x[7], 1))\n",
    "    .reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    ")\n",
    "average_vine_rating = average_vine_rating[0] / average_vine_rating[1]\n",
    "\n",
    "average_nonvine_rating = (\n",
    "    unioned_data.filter(lambda x: x[10] == \"N\")\n",
    "    .map(lambda x: (x[7], 1))\n",
    "    .reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    ")\n",
    "average_nonvine_rating = average_nonvine_rating[0] / average_nonvine_rating[1]\n",
    "\n",
    "difference = abs(abs(average_vine_rating) - abs(average_nonvine_rating))\n",
    "\n",
    "print(f\"Difference between vine and non-vine average: {difference}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar([\"Vine\", \"Non-Vine\"], [average_vine_rating, average_nonvine_rating])\n",
    "\n",
    "ax.set_title(\"Vine vs Non-Vine Customer Review Average\")\n",
    "ax.set_xlabel(\"Review Type\")\n",
    "ax.set_ylabel(\"Average Rating\")\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)\n",
    "    \n",
    "if MODE == \"PROD\":\n",
    "    filename = 'vine_rating_influence'\n",
    "    fig.savefig(filename + '.pdf')\n",
    "    fig.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it possible to predict the rating associated with a review by the sentiment of itâ€™s words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We predict that the sentiment of a word can be derived by an average of the ratings of the reviews that it occured in.\n",
    "this will act as a weight which can be used to preduct the rating of a given review\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def word_to_rating(x):\n",
    "    return_list = []\n",
    "\n",
    "    rating = x[0]\n",
    "    words = x[1]\n",
    "\n",
    "    for word in words:\n",
    "        return_list.append((word, rating))\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def clean_words(pair_rdd):\n",
    "    words = pair_rdd[1]\n",
    "\n",
    "    words = filter(remove_useless_words, words)\n",
    "    words = filter(remove_empty_words, words)\n",
    "    words = filter(remove_censored_swear_words, words)\n",
    "    words = filter(remove_words_without_alphanumeric, words)\n",
    "    words = filter(remove_single_letter_words, words)\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "# (rating, [word1, word2, ...])\n",
    "rating_to_review_words = (\n",
    "    unioned_data.map(lambda x: (x[7], x[13]))\n",
    "    .mapValues(preprocess)\n",
    "    .map(lambda x: (x[0], x[1].split()))\n",
    "    .filter(clean_words)\n",
    ")\n",
    "\n",
    "# [(word1, rating), (word2, rating), ...]\n",
    "review_words_to_ratings = rating_to_review_words.flatMap(word_to_rating)\n",
    "\n",
    "# [(word1, average_rating), (word2, average_rating), ...]\n",
    "average_word_rating = (\n",
    "    review_words_to_ratings.map(lambda x: (x[0], (x[1], 1)))\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "    .map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    ")\n",
    "\n",
    "\n",
    "word_frequency = (\n",
    "    review_words_to_ratings.map(lambda x: (x[0], 1))\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    "    .collectAsMap()\n",
    ")\n",
    "total_num_words = review_words_to_ratings.map(lambda x: x[0]).count()\n",
    "\n",
    "\n",
    "word_weights = average_word_rating.collectAsMap()\n",
    "\n",
    "\n",
    "def predict_rating_from_review(review):\n",
    "    words = review.split()\n",
    "\n",
    "    weights = []\n",
    "    for word in words:\n",
    "        if word in word_weights:\n",
    "            weights.append(word_weights[word])\n",
    "\n",
    "    # If none of the words in the input are in the weight set, return None instead of a prediction\n",
    "    if len(weights) == 0:\n",
    "        return None\n",
    "\n",
    "    return sum(weights) / len(weights)\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"really amazing product i love it so much absolutely incredible\",\n",
    "    \"it was alright not the best but not the worst\",\n",
    "    \"terrible i feel scammed i will return this this should be illegal\",\n",
    "    \"worst terrible refund\",\n",
    "    \"terrible\",\n",
    "    \"bad\",\n",
    "    \"good\",\n",
    "    \"perfect\",\n",
    "    \"thiswordisnotinthedataset\",\n",
    "]\n",
    "\n",
    "print(\"=== Rating predictions ===\")\n",
    "for example in examples:\n",
    "    print(f'Review text: \"{example}\"')\n",
    "    print(f\"Predicted Rating: {predict_rating_from_review(example)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
