{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Customer Review Analysis\n",
    "## By. Andrew Simmons & Jingnan Jin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Reference\n",
    "0. marketplace\n",
    "1. customer_id\n",
    "2. review_id\n",
    "3. product_id\n",
    "4. product_parent\n",
    "5. product_title\n",
    "6. product_category\n",
    "7. star_rating - [1-5]\n",
    "8. helpful_votes\n",
    "9. total_votes\n",
    "10. vine\n",
    "11. verified_purchase\n",
    "12. review_headline\n",
    "13. review_body\n",
    "14. review_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import html\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import findspark\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"AmazonCustomerReviewAnalysis\").setMaster(\"local[*]\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Constants\"\"\"\n",
    "\n",
    "PLOT_DIMENSIONS = (20, 10)\n",
    "\n",
    "with open('useless_words.txt') as f:\n",
    "    USELESS_WORDS = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Process list of files to separate by category\"\"\"\n",
    "\n",
    "data_dir = Path('sample_data')\n",
    "data_files = [file for file in data_dir.glob('*.tsv.gz') if file.name.startswith('amazon_reviews_us_')]\n",
    "\n",
    "data_categories = defaultdict(list)\n",
    "for file in data_files:\n",
    "    category_name = file.name[18:-13].replace('_', ' ')\n",
    "    data_categories[category_name].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create mapping of category names to unioned RDD\"\"\"\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "    data_categories[key] = sc.union([sc.textFile(str(file)) for file in value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove headers from data\"\"\"\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "    data_categories[key] = value.filter(lambda x: not x.startswith('marketplace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split TSV\"\"\"\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "    data_categories[key] = value.map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preprocess certain values\"\"\"\n",
    "\n",
    "for key, value in data_categories.items():\n",
    "    data_categories[key] = value.map(lambda x: (\n",
    "        x[0],\n",
    "        x[1],\n",
    "        x[2],\n",
    "        x[3],\n",
    "        x[4],\n",
    "        x[5],\n",
    "        x[6],\n",
    "        int(x[7]),\n",
    "        int(x[8]),\n",
    "        int(x[9]),\n",
    "        x[10],\n",
    "        x[11],\n",
    "        x[12],  # TODO: Determine if headlines are HTML escaped like the bodies\n",
    "        html.unescape(x[13]),  # TODO: Consider how to handle <br /> tags\n",
    "        x[14]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many records exist in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_counts = []\n",
    "for key, value in data_categories.items():\n",
    "    record_counts.append((key, value.count()))\n",
    "\n",
    "categories, counts = zip(*sorted(record_counts, key=itemgetter(1)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar(categories, counts)\n",
    "\n",
    "ax.set_title('Amazon Review Counts by Category')\n",
    "ax.set_xlabel('Product Category')\n",
    "ax.set_ylabel('Review Counts')\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)\n",
    "\n",
    "print(f'Total number of reviews in dataset: {sum(counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall, how satisfied are customers of each product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_review_by_category = []\n",
    "for key, value in data_categories.items():\n",
    "    star_ratings = value.map(lambda x: int(x[7]))\n",
    "    average_review_by_category.append((key, star_ratings.mean()))\n",
    "\n",
    "categories, ratings = zip(*sorted(average_review_by_category, key=itemgetter(1)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(PLOT_DIMENSIONS)\n",
    "\n",
    "rects = ax.bar(categories, ratings)\n",
    "\n",
    "ax.set_title('Average Product Category Rating')\n",
    "ax.set_xlabel('Product Category')\n",
    "ax.set_ylabel('Average Rating')\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the distribution of review scores change between product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_distributions = {}\n",
    "for key, value in data_categories.items():\n",
    "    review_distributions[key] = sorted(value.map(lambda x: (x[7], 1)).reduceByKey(lambda x, y: x + y).collect(), key=itemgetter(0))\n",
    "\n",
    "num_columns = 3\n",
    "\n",
    "fig, ax = plt.subplots(nrows=math.ceil(len(review_distributions.keys()) / num_columns),\n",
    "                       ncols=num_columns)\n",
    "fig.set_size_inches((20, 100))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (key, value) in enumerate(review_distributions.items()):\n",
    "    stars, counts = zip(*value)\n",
    "    \n",
    "    rects = ax[i].bar(stars, counts)\n",
    "    \n",
    "    # TODO: Calculate mean more efficiantly\n",
    "    total = 0\n",
    "    for j in range(len(stars)):\n",
    "        total += stars[j] * counts[j]\n",
    "    mean = total / sum(counts)\n",
    "    \n",
    "    # TODO: Include a median line\n",
    "    mean_line = ax[i].axvline(mean, color='red', linestyle='--')\n",
    "    ax[i].legend([mean_line], ['Mean Category Rating'])\n",
    "    \n",
    "    ax[i].set_title(f'Ratings Frequency Distribution for {key} category')\n",
    "    ax[i].set_xlabel('Star Rating')\n",
    "    ax[i].set_ylabel('Rating Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are most used in each category at each rating for review headlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "category: {\n",
    "    1: [n most common words],\n",
    "    2: ...\n",
    "},\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_REVIEWS = {\n",
    "    'One Star',\n",
    "    'Two Stars',\n",
    "    'Three Stars',\n",
    "    'Four Stars',\n",
    "    'Five Stars',\n",
    "}\n",
    "\n",
    "def remove_default_headlines(headline):\n",
    "    \"\"\"Remove default headlines\"\"\"\n",
    "    if headline in DEFAULT_REVIEWS:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess(headline):\n",
    "    \n",
    "    # Convert multiple spaces to a single space\n",
    "    headline = re.sub(r'\\s+', ' ', headline, flags=re.I)\n",
    "    \n",
    "    # Remove space at the end of a headline\n",
    "    # TODO: Make this work correctly\n",
    "    #headline = re.sub(r'\\s+$', '', headline)\n",
    "    \n",
    "    # Remove punctuation that is found at the end of words\n",
    "    headline = re.sub(r'[,.!?]', '', headline)\n",
    "    \n",
    "    # Remove apostrophies as to group together both spellings of a word\n",
    "    headline = re.sub(r\"'\", '', headline)\n",
    "    \n",
    "    return headline.lower()\n",
    "\n",
    "\n",
    "def remove_useless_words(headline_word):\n",
    "    \"\"\"Remove stop words and elipses\"\"\"\n",
    "\n",
    "    if headline_word in USELESS_WORDS:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_empty_words(headline_word):\n",
    "    if len(headline_word) == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_censored_swear_words(headline_word):\n",
    "    \"\"\"Amazon appears to have censored swear words by keeping the first character\n",
    "    and replacing the other characters with astrisks. These are not useful to us.\n",
    "    \"\"\"\n",
    "    \n",
    "    if re.match('^[a-z]\\*+$', headline_word) is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_words_without_alphanumeric(headline_word):\n",
    "    if re.match('[a-z0-9]', headline_word) is None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_numbers(headline_word):\n",
    "    \"\"\"Remove words that consist of nothing but numbers\"\"\"\n",
    "    if re.match('^[0-9]+$', headline_word) is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# TODO: Remove single letter words\n",
    "\n",
    "\n",
    "POSSIBLE_RATINGS = [1, 2, 3, 4, 5]\n",
    "\n",
    "resulting_word_frequencies = defaultdict(dict)\n",
    "for key, value in data_categories.items():\n",
    "    rating_words = {}\n",
    "    for i in POSSIBLE_RATINGS:\n",
    "        reviews = value.filter(lambda x: x[7] == i)\n",
    "        headlines = reviews.map(lambda x: x[12]).filter(remove_default_headlines).map(preprocess)\n",
    "        \n",
    "        headline_words = headlines.flatMap(lambda x: x.split()).filter(remove_useless_words).filter(remove_empty_words).filter(remove_censored_swear_words).filter(remove_words_without_alphanumeric)\n",
    "        word_frequencies = headline_words.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda x: x[1], ascending=False).map(lambda x: x[0])\n",
    "        \n",
    "        resulting_word_frequencies[key][i] = word_frequencies.take(3)\n",
    "\n",
    "# Output results\n",
    "for category in resulting_word_frequencies.keys():\n",
    "    print(f'{category}:')\n",
    "    for rating in POSSIBLE_RATINGS:\n",
    "        print(f'  {rating}')\n",
    "        words = resulting_word_frequencies[category][rating]\n",
    "        for word in words:\n",
    "            print(f'    {word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are most used in each category at each rating for review bodies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_word_frequencies = defaultdict(dict)\n",
    "for key, value in data_categories.items():\n",
    "    rating_words = {}\n",
    "    for i in POSSIBLE_RATINGS:\n",
    "        reviews = value.filter(lambda x: x[7] == i)\n",
    "        headlines = reviews.map(lambda x: x[13]).map(preprocess)\n",
    "        \n",
    "        headline_words = headlines.flatMap(lambda x: x.split()).filter(remove_useless_words).filter(remove_empty_words).filter(remove_censored_swear_words).filter(remove_words_without_alphanumeric)\n",
    "        word_frequencies = headline_words.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda x: x[1], ascending=False).map(lambda x: x[0])\n",
    "        \n",
    "        resulting_word_frequencies[key][i] = word_frequencies.take(3)\n",
    "\n",
    "# Output results\n",
    "for category in resulting_word_frequencies.keys():\n",
    "    print(f'{category}:')\n",
    "    for rating in POSSIBLE_RATINGS:\n",
    "        print(f'  {rating}')\n",
    "        words = resulting_word_frequencies[category][rating]\n",
    "        for word in words:\n",
    "            print(f'    {word}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
